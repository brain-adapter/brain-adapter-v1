trainer:
  task: train_and_test_with_best
  seed: 2024
  save_directory: /root/autodl-tmp/md-ckpts
  check_val_every_n_epoch: 1
  max_epochs: 5
  num_devices: 1

  checkpoint:
    dirpath: /root/autodl-tmp/ckpts
    monitor: val_loss
    filename: lit-{val_loss:.4f}
    save_top_k: 1
    mode: min
    every_n_epochs: 1
    save_last: false

# for Tensorboard logger
logger:
    save_dir: /root/tf-logs
    sub_dir: logs
    name: brain-vision-model
    version: 5-95
    default_hp_metric: false

lightning:
  name: model.lightnings.LitBrainVisionModel
  pretrained_model_path: null

model:
  name: model.models.BrainVisionModel

  vision_config:
    encoder_name: model.modules.VisionPerceiver

    input_dim: 1024
    hidden_size: 768
    num_attention_heads: 12
    num_layers: 4
    num_tokens: 257

    projection_dim: 768

  eeg_config:
    encoder_name: model.modules.EEGTransformer

    num_channels: 128
    num_samples: 440
    patch_size: 4
    hidden_size: 768
    num_layers: 8
    num_attention_heads: 12
    mlp_ratio: 1.0

    projection_dim: 768


dataset: 
  name: data.dataset.EEGImageNetDataset

  num_workers: 4 # num_devices * 4
  subject: 0 # 0 means using data of all subjects
  batch_size: 16

  eeg_data_path: /root/autodl-tmp/data/eeg-imagenet/eeg_5_95_std.pth
  splitter_path: /root/autodl-tmp/data/eeg-imagenet/block_splits_by_image_all.pth
  clip_embeds_path: /root/autodl-tmp/data/eeg-imagenet/embeds/clip-vit-l-14-embeds.bin

  merge_train_and_val: true


optimizer:
  name: torch.optim.AdamW
  params:
    lr: 2.e-5
    weight_decay: 0.01

# scheduler:
#   name: flash.core.optimizers.LinearWarmupCosineAnnealingLR
#   params:
#     warmup_epochs: 5
#     max_epochs: 50
#     warmup_start_lr: 5.e-5
#     eta_min: 4.e-5

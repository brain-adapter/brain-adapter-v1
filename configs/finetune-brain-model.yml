trainer:
  task: train_and_test_with_best
  seed: 2024
  save_directory: /root/autodl-tmp/pretrained
  check_val_every_n_epoch: &interval 1
  max_epochs: 10
  num_devices: 1

  checkpoint:
    dirpath: /root/autodl-tmp/ckpts
    monitor: val_loss
    filename: lit-{val_loss:.4f}
    save_top_k: 1
    mode: min
    every_n_epochs: *interval
    save_last: false

# for Tensorboard logger
logger:
    save_dir: /root/tf-logs
    sub_dir: logs
    name: eeg-model-finetune-4
    version: 5-95
    default_hp_metric: false

lightning:
  name: model.lightnings.LitBrainKDModel

  pretrained_model_path: /root/autodl-tmp/pretrained/eeg-model
  clip_model_path: &clip_model_path /root/autodl-tmp/pretrained/clip-vit-large-patch14-336

model: null


dataset: 
  name: data.dataset.EEGImageNetDataset

  num_workers: 2 # num_devices * 2
  subject: 4
  batch_size: 4

  image_ext: JPEG

  image_root_path: /root/autodl-tmp/data/eeg-imagenet/images
  eeg_data_path: /root/autodl-tmp/data/eeg-imagenet/eeg_5_95_std.pth
  splitter_path: /root/autodl-tmp/data/eeg-imagenet/block_splits_by_image_single.pth
  clip_model_path: *clip_model_path

  merge_train_and_val: true


optimizer:
  name: torch.optim.AdamW
  params:
    lr: 2.e-5
    weight_decay: 0.05
